# -*- coding: utf-8 -*-
"""KMeansplusplus

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10uEdhlHOxqt_iaKNQ3oOMR_e0zORal8E
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import silhouette_score
import os


# Function to load the dataset from a file
def load_dataset(dataset):
    # Check if the specified dataset file exists, if not raise an error
    if not os.path.isfile(dataset):
        raise FileNotFoundError(f"The file {dataset} does not exist.")
    data = []
        # Open and read the dataset file
    with open(dataset, 'r') as file:
        for line in file:
           # Convert all elements starting from the second element of each line to float
            numeric_values = [float(part) for part in line.strip().split()[1:]]
            # Ensure there are at least two numeric values per line
            if len(numeric_values) < 2:
                raise ValueError("The dataset must have at least 2 numeric values per line.")
            data.append(numeric_values)
    return np.array(data)

# Function to compute Euclidean distance between two points

def ComputeDistance(point1, point2):
    return np.sqrt(np.sum((point1 - point2) ** 2))

# Function to initialize centroids for clustering

def initialSelection(points, k):
    np.random.seed(42) # Set seed for reproducibility
    centroids = [points[np.random.choice(len(points))]]
    for _ in range(1, k):
        distances = np.array([min([np.linalg.norm(point - centroid) ** 2 for centroid in centroids]) for point in points])
        probabilities = distances / distances.sum()
        cumulative_probabilities = probabilities.cumsum()
        r = np.random.rand()
        i = np.where(cumulative_probabilities >= r)[0][0]
        centroids.append(points[i])
    return np.array(centroids)

# Function to assign cluster IDs to each point
def assignClusterIds(points, centroids):
    distances = np.sqrt(((points - centroids[:, np.newaxis])**2).sum(axis=2))
    return np.argmin(distances, axis=0)

# Function to recompute centroids based on the current cluster assignments
def computeClusterRepresentatives(points, labels, k):
    return np.array([points[labels == i].mean(axis=0) for i in range(k)])


# Main function to execute the clustering algorithm
def clustername(points, k, max_iter=100):
    centroids = initialSelection(points, k)
    for i in range(max_iter):
        labels = assignClusterIds(points, centroids)
        new_centroids = computeClusterRepresentatives(points, labels, k)
        if np.allclose(centroids, new_centroids, atol=1e-4):
            break
        centroids = new_centroids
    return labels, centroids

# Function to plot and save the silhouette scores as a function of k
def plot_silhouette(silhouette_scores):
    plt.figure(figsize=(10, 6))
    k_values = range(2, len(silhouette_scores) + 2)
    plt.plot(k_values, silhouette_scores, 'bx-')
    plt.title('Silhouette Scores for Different Values of k')
    plt.xlabel('k')
    plt.ylabel('Silhouette Score')
    plt.xticks(k_values)
    plt.grid(True)
    plt.savefig('silhouette_scores.png')
    plt.show()


# Function to compute the silhouette scores for a range of k values
def compute_silhouette_scores(points, max_k):
    silhouette_scores = []
    for k in range(2, max_k + 1):
        labels, centroids = clustername(points, k)
        score = silhouette_score(points, labels)
        silhouette_scores.append(score)
    return silhouette_scores

# Main executable block that handles the overall process flow
if __name__ == "__main__":
    try:
        original_data = load_dataset("dataset")
        silhouette_scores = compute_silhouette_scores(original_data, 9)
        plot_silhouette(silhouette_scores)
    except Exception as e:
        print(f"An error occurred: {e}")